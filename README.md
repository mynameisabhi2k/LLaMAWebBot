# ğŸ§  Website Q&A Bot using LangChain + ChromaDB + LLaMA

This project is an interactive **Q&A chatbot** that ingests the content of any website, stores it as semantic embeddings in a **Chroma vector database**, and answers user queries using an open-source **LLaMA model** via HuggingFace.

---

## ğŸš€ Features

- ğŸŒ Extracts clean website content (text only)
- âœ‚ï¸ Splits content into smart chunks
- ğŸ§  Converts chunks to embeddings using HuggingFace embeddings
- ğŸ—‚ Stores vectors in **ChromaDB** for fast retrieval
- ğŸ” Combines retrieved context with your question
- ğŸ¤– Responds with high-quality answers using an LLaMA-based model

---

## ğŸ§° Tech Stack

| Tool | Purpose |
|------|---------|
| **LangChain** | Build chains of LLM + retriever |
| **ChromaDB** | Vector database for document search |
| **Sentence Transformers** | Embeddings (`all-MiniLM-L6-v2`) |
| **HuggingFace Transformers** | Load open-source LLMs like LLaMA |
| **Jupyter Notebook** | Prototype, debug, and iterate |

---

ğŸ§ª Example Use Case
Website: https://lmsys.org/blog/2023-03-30-vicuna/

Questions you can ask:

â€œWhat is Vicuna?â€

â€œHow is it different from Alpaca?â€

â€œWho developed it?â€
